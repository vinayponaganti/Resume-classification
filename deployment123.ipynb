{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f1d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "from win32com import client\n",
    "import os\n",
    "from docx import Document \n",
    "import PyPDF2\n",
    "import textract\n",
    "import spacy\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sweetviz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea107d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "# Set page config\n",
    "st.set_page_config(page_title=\"My Streamlit App\", page_icon=\":smiley:\", layout=\"wide\")\n",
    "\n",
    "# Set background image\n",
    "def add_bg_from_local(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-image: url(data:image/{\"png\"};base64,{encoded_string.decode()});\n",
    "        background-size: cover\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    "    )\n",
    "#add_bg_from_local(\"D:\\dummy\\strimlate\\strimlate\\white.webp\")\n",
    "    \n",
    "# Add title with CSS styles\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: #333333;\n",
    "}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"GROUP 2 Project\")\n",
    "# load the pre-trained LSTM model\n",
    "loaded_model=pickle.load(open(r'modelNLP1.pkl','rb'))\n",
    "\n",
    "# Assigning path based on the category\n",
    "files1 = glob(\"D:\\\\dataScience\\\\projects\\\\NLP_RESUME_CLASIFICATION\\\\data_sets\\\\classified_Resumes\\\\Peoplesoft resumes\\\\*\")\n",
    "files2 = glob(\"D:\\\\dataScience\\\\projects\\\\NLP_RESUME_CLASIFICATION\\\\data_sets\\\\classified_Resumes\\\\React JS Developer\\\\*\")\n",
    "files3 = glob(\"D:\\\\dataScience\\\\projects\\\\NLP_RESUME_CLASIFICATION\\\\data_sets\\\\classified_Resumes\\\\SQL Developer Lightning insight\\\\*\")\n",
    "files4 = glob(\"D:\\\\dataScience\\\\projects\\\\NLP_RESUME_CLASIFICATION\\\\data_sets\\\\classified_Resumes\\\\workday resumes\\\\*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ed287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion for reading doc files\n",
    "def docReader(doc_file_name): \n",
    "    ## 1) Initiate an object that interfaces to Word\n",
    "    word = client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False \n",
    "    \n",
    "    ## 2) Open the Word document to read in\n",
    "    _ = word.Documents.Open(doc_file_name)\n",
    "\n",
    "    ## 3) Extract the paragraphs and close the connections\n",
    "    doc = word.ActiveDocument\n",
    "    paras = doc.Range().text    \n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return paras    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a7158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convef1():\n",
    "\n",
    "   # Importing the data present in first file (People soft)\n",
    "        data1 = []\n",
    "        for i in range(len(files1)):\n",
    "            if files1[i].endswith('docx'):\n",
    "                x = docx2txt.process(files1[i]);\n",
    "                data1.append(x)\n",
    "            if files1[i].endswith('doc'):\n",
    "                y = docReader(files1[i]);\n",
    "                data1.append(y)\n",
    "                [a for a in y.replace('\\x07', '\\r').split('\\r') if a]\n",
    "            z = None  # define a default value for z\n",
    "            if files1[i].endswith('pdf'):\n",
    "                z = PyPDF2.PdfReader(files1[i]);\n",
    "                z1 = ''\n",
    "                for j in range(len(z.pages)):\n",
    "                    m = z.pages[j].extract_text()\n",
    "                    z1 = z1 + m\n",
    "                data1.append(z1)\n",
    "\n",
    "\n",
    "        data1 = pd.DataFrame(data=data1,columns=['data']) # converting to DataFrame\n",
    "        data1['category'] = 'Peoplesoft' # Creating column with column name category and assigning \"peoplesoft\" to every cell\n",
    "        # Adding Name column and assinging name\n",
    "        name1 = []\n",
    "        for i in range(len(files1)):\n",
    "            tem = files1[i].split('\\\\');\n",
    "            name1.append(tem[-1])\n",
    "            names1 = []\n",
    "        for i in range(len(name1)):\n",
    "            d = name1[i].split('.')\n",
    "            names1.append(d[0])\n",
    "        names1 = pd.DataFrame(data = names1,columns=[\"Name\"])\n",
    "        data1 = pd.concat([data1,names1],axis=1)\n",
    "        return data1\n",
    "\n",
    "        \n",
    "def convef2():\n",
    "    # Importing the data present in second file (React JS Developer)\n",
    "        data2 = []\n",
    "        for i in range(len(files2)):\n",
    "            if files2[i].endswith('docx'):\n",
    "                x = docx2txt.process(files2[i]);\n",
    "                data2.append(x)\n",
    "            if files2[i].endswith('doc'):\n",
    "                y = docReader(files2[i]);\n",
    "                data2.append(y)\n",
    "                [a for a in y.replace('\\x07', '\\r').split('\\r') if a]\n",
    "            if files2[i].endswith('pdf'):\n",
    "                z = PyPDF2.PdfReader(files2[i]);\n",
    "                z1 = ''\n",
    "                for j in range(len(z.pages)):\n",
    "                    m = z.pages[j].extract_text()\n",
    "                    z1 = z1 + m\n",
    "                data2.append(z1)\n",
    "        data2 = pd.DataFrame(data=data2,columns=['data'])\n",
    "        data2['category'] = 'React JS Developer' # Creating column with column name category and assigning \"React JS Developer\" to every cell\n",
    "        # Adding Name column and assinging name\n",
    "        name2 = []\n",
    "        for i in range(len(files2)):\n",
    "            tem = files2[i].split('\\\\');\n",
    "            name2.append(tem[-1])\n",
    "        names2 = []\n",
    "        for i in range(len(name2)):\n",
    "            d = name2[i].split('.')\n",
    "            names2.append(d[0])\n",
    "        names2 = pd.DataFrame(data = names2,columns=[\"Name\"])\n",
    "        data2 = pd.concat([data2,names2],axis=1)\n",
    "        return data2\n",
    "\n",
    "def convef3():\n",
    "    # Importing the data present in third file (SQL Developer)\n",
    "    data3 = []\n",
    "    for i in range(len(files3)):\n",
    "        if files3[i].endswith('docx'):\n",
    "            x = docx2txt.process(files3[i]);\n",
    "            data3.append(x)\n",
    "        if files3[i].endswith('doc'):\n",
    "            y = docReader(files3[i]);\n",
    "            data3.append(y)\n",
    "            [a for a in y.replace('\\x07', '\\r').split('\\r') if a]\n",
    "        if files3[i].endswith('pdf'):\n",
    "            z = PyPDF2.PdfReader(files3[i]);\n",
    "            z1 = ''\n",
    "            for j in range(len(z.pages)):\n",
    "                m = z.pages[j].extract_text()\n",
    "                z1 = z1 + m\n",
    "            data3.append(z1)\n",
    "    data3 = pd.DataFrame(data=data3,columns=['data'])\n",
    "    data3['category'] = 'SQL Developer' # Creating column with column name category and assigning \"SQL Developer\" to every cell \n",
    "    # Adding Name column and assinging name\n",
    "    name3 = []\n",
    "    for i in range(len(files3)):\n",
    "        tem = files3[i].split('\\\\');\n",
    "        name3.append(tem[-1])\n",
    "    names3 = []\n",
    "    for i in range(len(name3)):\n",
    "        d = name3[i].split('.')\n",
    "        names3.append(d[0])\n",
    "    names3 = pd.DataFrame(data = names3,columns=[\"Name\"])\n",
    "    data3 = pd.concat([data3,names3],axis=1)\n",
    "    return data3\n",
    "\n",
    "def convef4():\n",
    "    # Importing the data present in 4th file (workday)\n",
    "    data4 = []\n",
    "    for i in range(len(files4)):\n",
    "        if files4[i].endswith('docx'):\n",
    "            x = docx2txt.process(files4[i]);\n",
    "            data4.append(x)\n",
    "        if files4[i].endswith('doc'):\n",
    "            y = docReader(files4[i]);\n",
    "            data4.append(y)\n",
    "            [a for a in y.replace('\\x07', '\\r').split('\\r') if a]\n",
    "        if files4[i].endswith('pdf'):\n",
    "            z = PyPDF2.PdfReader(files4[i]);\n",
    "            z1 = ''\n",
    "            for j in range(len(z.pages)):\n",
    "                m = z.pages[j].extract_text()\n",
    "                z1 = z1 + m\n",
    "            data4.append(z1)\n",
    "    data4 = pd.DataFrame(data=data4,columns=['data'])\n",
    "    data4['category'] = 'workday' # Creating column with column name category and assigning \"workday\" to every cell \n",
    "    # Adding Name column and assinging name\n",
    "    name4 = []\n",
    "    for i in range(len(files4)):\n",
    "        tem = files4[i].split('\\\\');\n",
    "        name4.append(tem[-1])\n",
    "    names4 = []\n",
    "    for i in range(len(name4)):\n",
    "        d = name4[i].split('.')\n",
    "        names4.append(d[0])\n",
    "    names4 = pd.DataFrame(data = names4,columns=[\"Name\"])\n",
    "    data4 = pd.concat([data4,names4],axis=1)\n",
    "    return data4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7c1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addata():\n",
    "    data1=convef1()\n",
    "    data2=convef2()\n",
    "    data3=convef3()\n",
    "    data4=convef4()\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    lst = [data1,data2,data3,data4]\n",
    "    for subDF in lst:\n",
    "        df = pd.concat([df, subDF],ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da745882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skile():\n",
    "    df=addata()\n",
    "    test = spacy.load('en_core_web_sm')\n",
    "    Skills = []\n",
    "    for i in range(len(df.data)):\n",
    "        ts = test(\" \".join(df.data[i].split('\\n'))) # we have splitted our data with '\\n' and rejoined with space. \n",
    "        tt = []\n",
    "        for ent in ts.ents:\n",
    "            if ent.label_.upper() == 'ORG':\n",
    "                tt.append(ent.text)\n",
    "        Skills.append(tt) # appending all skills to the list skills\n",
    "    df['skills']=0  # creating new columns skills and assiging 0 to every column\n",
    "    for i in range(len(df.skills)):\n",
    "            df.skills[i] = Skills[i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a23e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda():\n",
    "    df=skile()\n",
    "    for i in range(len(df.skills)):\n",
    "        lower_words=[Text.lower() for Text in df.skills[i]]\n",
    "    df.skills[i] = lower_words\n",
    "    for i in range(len(df.skills)):\n",
    "        ab =[]\n",
    "    for j in range(len(df.skills[i])):\n",
    "        jk = re.split(r'[,(\\n\\t:]', df.skills[i][j]) # splitting the objects using ,,(,\\n,\\t,:\n",
    "        ab = jk + ab\n",
    "        df.skills[i] = ab\n",
    "    # finding the duplicat values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db72f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplica():\n",
    "    df=eda()\n",
    "    # finding the duplicat values\n",
    "    for i in range(len(df.skills)):\n",
    "        numbers = df.skills[i]\n",
    "        counts = dict(Counter(numbers))\n",
    "        duplicates = {key:value for key, value in counts.items() if value > 1}\n",
    "        st.write(duplicates)\n",
    "        df= duplica()\n",
    "    for i in range(len(df.skills)):\n",
    "        lm = set(df.skills[i])\n",
    "        df.skills[i] = list(lm)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf8902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remoo():\n",
    "    df=duplica()\n",
    "    \n",
    "        # Removing the unwanted data like '',' ','s','cs' which contains length upto 2\n",
    "    for i in range(len(df.skills)):\n",
    "        er = []\n",
    "        for j in range(len(df.skills[i])):\n",
    "            if (len(df.skills[i][j]) >= 3) :\n",
    "                ab = df.skills[i][j]\n",
    "                er = er + [ab]\n",
    "        df.skills[i] = er\n",
    "    # Removing all punctuation\n",
    "\n",
    "    for i in range(len(df.skills)):\n",
    "        for j in range(len(df.skills[i])):\n",
    "            df.skills[i][j] = df.skills[i][j].translate(str.maketrans('','',string.punctuation))\n",
    "    for i in range(len(df.skills)):\n",
    "        for j in range(len(df.skills[i])):\n",
    "            df.skills[i][j] = ''.join([i for i in df.skills[i][j] if not i.isdigit()])\n",
    "    # Removing all spaces \n",
    "   \n",
    "    for i in range(len(df.skills)):\n",
    "        for j in range(len(df.skills[i])):\n",
    "            df.skills[i][j] = word_tokenize(df.skills[i][j])\n",
    "            df.skills[i][j] =  ' '.join(df.skills[i][j])\n",
    "    # Removing the unwanted data like '',' ','s','cs' which contains length upto 2\n",
    "    \n",
    "    for i in range(len(df.skills)):\n",
    "        er = []\n",
    "        for j in range(len(df.skills[i])):\n",
    "            if (len(df.skills[i][j]) >= 3) :\n",
    "                ab = df.skills[i][j]\n",
    "                er = er + [ab]\n",
    "        df.skills[i] = er\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35678a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coppy():\n",
    "   df=remoo()\n",
    "   df1 = df.copy(deep=True) # it will take copy of df \n",
    "   for i in range(len(df1.skills)):\n",
    "        df1.skills[i] = \" \".join(df1.skills[i]) # converting list into string\n",
    "   for i in range(len(df1.skills)):\n",
    "    df1.skills[i] = word_tokenize(df1.skills[i]) # tokenization\n",
    "    nltk.download('stopwords') # importing stop words\n",
    "\n",
    "    my_stop_words = stopwords.words('english')\n",
    "    my_stop_words.append(' ')\n",
    "    my_stop_words.append('&') # adding reqiued stop words\n",
    "    # removing stop words\n",
    "    for i in range(len(df1.skills)):    \n",
    "        df1.skills[i] = [word for word in df1.skills[i] if not word in my_stop_words ]\n",
    "    # joining the words into single document (removing the tokenization)\n",
    "    for i in range(len(df1.skills)):\n",
    "        df1.skills[i] =  ' '.join(df1.skills[i])\n",
    "    # Lemmatization\n",
    "    Lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(df1.skills)):\n",
    "        lemmas = []\n",
    "        for token in df1.skills[i].split():\n",
    "            lemmas.append(Lemmatizer.lemmatize(token))\n",
    "        df1.skills[i] = lemmas\n",
    "    # joining the words into single document (removing the tokenization)\n",
    "    for i in range(len(df1.skills)):\n",
    "        df1.skills[i] =  ' '.join(df1.skills[i])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b3ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text():\n",
    "    df1=coppy()\n",
    "    df=remoo()\n",
    "    for i in range(len(df1.skills)):\n",
    "        df2 = [skills.strip() for skills in df1.skills] # adding all rows to one column\n",
    "        text = \" \".join(df2)\n",
    "        text_tokens = word_tokenize(text)\n",
    "        text1 = pd.DataFrame(data=text_tokens,columns=['text'])\n",
    "        text1['y'] = 1\n",
    "    df3 = []\n",
    "    for i in range(len(df.skills)):\n",
    "        df3 = df3 + df.skills[i]\n",
    "    # Lemmatization\n",
    "    Lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for token in df3:\n",
    "        lemmas.append(Lemmatizer.lemmatize(token))\n",
    "    df3 = pd.DataFrame(data=df3,columns = ['data'])\n",
    "    df3['y'] = 1\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "719bf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extaraction():\n",
    "    df1=coppy()\n",
    "    x = df1['skills']\n",
    "    y = df1['category']\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True)\n",
    "    word_vectorizer.fit(x)\n",
    "    x = word_vectorizer.transform(x)\n",
    "    LE = LabelEncoder()\n",
    "    y = LE.fit_transform(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=30, test_size=0.20, shuffle = True, stratify=y)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb4394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    x_train, x_test, y_train, y_test=extaraction()\n",
    "    Knn = KNeighborsClassifier(n_neighbors=5,p=2)\n",
    "    Knn.fit(x_train, y_train)\n",
    "    y_pred_train = Knn.predict(x_train)\n",
    "    y_pred_test = Knn.predict(x_test)\n",
    "    \n",
    "    a21 = accuracy_score(y_train, y_pred_train)\n",
    "    a22 =accuracy_score(y_test, y_pred_test)\n",
    "    r21 = recall_score(y_train, y_pred_train,average = 'macro')\n",
    "    r22 = recall_score(y_test, y_pred_test,average = 'macro')\n",
    "    p21 = precision_score(y_train, y_pred_train,average = 'macro')\n",
    "    p22 = precision_score(y_test, y_pred_test,average = 'macro')\n",
    "    f21 = f1_score(y_train, y_pred_train,average = 'macro')\n",
    "    f22 = f1_score(y_test, y_pred_test,average = 'macro')\n",
    "    m2 = 'KNN'\n",
    "    model = {'model':[m2],\n",
    "         \"train accuracy\":[a21],'test accuracy':[a22],\n",
    "         'train recall':[r21],\"test recall\":[r22],\n",
    "         'train precision':[p21],\"test precision\":[p22],\n",
    "         'tain f1_score':[p21],'test f1_score':[f22]}\n",
    "    model = pd.DataFrame(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n",
      "C:\\Users\\Vinay Sai\\AppData\\Local\\Temp\\ipykernel_27080\\3937734363.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.skills[i] = skills[i]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #giving title\n",
    "    st.title('Forcasting future data web app')\n",
    "\n",
    "    #getting input variable from users\n",
    "    n_future=st.text_input('Number of future data')\n",
    "\n",
    "    diagnosis=''\n",
    "    \n",
    "    \n",
    "    \n",
    "    df=model()\n",
    "    #creating button for prediction\n",
    "    st.write(df)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63ab22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
